{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9da5edc",
   "metadata": {},
   "source": [
    "# Machine Learning, AI and Optimization Project\n",
    "## Project Title: *To bee or not to bee* üêù \n",
    "\n",
    "### Courses\n",
    "- IG.2412 (Machine Learning)\n",
    "- IG.2411 (AI and Optimization)\n",
    "\n",
    "> This project is shared across both courses. Follow only the parts relevant to the course(s) you're enrolled in.\n",
    "\n",
    "---\n",
    "\n",
    "## I. Project Overview\n",
    "**Goal**: Detect and classify bees and bumblebees from other insects using a dataset of 347 high-resolution images.\n",
    "\n",
    "- **Images 1‚Äì250**: Provided with segmentation masks and labels (`bug type` and `species`)\n",
    "\n",
    "<span style=\"color:green\"> Dataset is stored in the `data` dir: `../data` to access from `work` dir  </span>\n",
    "- **Images 251‚Äì347**: Provided only with segmentation masks (for final evaluation)\n",
    "\n",
    "---\n",
    "\n",
    "## II. Expected Deliverables (Due:  June 2nd, 2025 at 12:30 PM)\n",
    "\n",
    "### 1. Report (PDF)\n",
    "- Description of extracted features\n",
    "- Algorithms and methods used\n",
    "- Visualizations and interpretations\n",
    "\n",
    "### 2. CSV File (Results)\n",
    "- Columns: `\"ID\"`, `\"bug type\"`\n",
    "- Predictions on test images (251‚Äì347) using your best model\n",
    "\n",
    "---\n",
    "\n",
    "## III. Tasks Breakdown\n",
    "\n",
    "### III.1 Feature Extraction [7 points]\n",
    "Extract the following from training data:\n",
    "- Shape & symmetry features (from provided Jupyter Notebook) [IG.2411]\n",
    "- Pixel ratio: bug pixels / total image pixels\n",
    "- RGB statistics inside bug mask:\n",
    "  - Min, Max, Mean [IG.2412]\n",
    "  - Median, Std Deviation [IG.2412]\n",
    "- Two or more **custom features** (can be inside or outside mask)\n",
    "\n",
    "---\n",
    "\n",
    "### III.2 Data Visualization [5 points] \n",
    "\n",
    "<span style=\"color:green\"> cf. IG.2412, Week 12-13 slides </span>\n",
    "\n",
    "Include and comment on:\n",
    "- Class distribution plots (`bug type` and `species`)\n",
    "- PCA projection (2D)\n",
    "- Two or more **non-linear projections** (e.g.,MDS, ISOMAP, LLE, t-SNE, etc. ) [IG.2412]\n",
    "\n",
    "---\n",
    "\n",
    "### III.3 Machine Learning & Deep Learning    [6 + 2 points] \n",
    "\n",
    "<span style=\"color:green\"> cf. IG.2412, Classification - Weeks 6,7,9,11 slides; Clustering - Weeks 15,16,18 slides </span>\n",
    "\n",
    "**Required Models:**\n",
    "- 2 supervised, non-DL, non-ensemble methods (<span style=\"color:green\"> cf. IG.2412, Lecture 1-3 </span>) [IG.2412]\n",
    "- 1 ensemble supervised method (<span style=\"color:green\"> cf. IG.2412, Lecture 4 </span>) [IG.2412]\n",
    "- 2 clustering methods (<span style=\"color:green\"> cf. IG.2412, Lecture 6,7 </span>) [IG.2412]\n",
    "- 1 supervised method with hyperparameter tuning (Grid/Randomized Search) [IG.2411]\n",
    "\n",
    "**Evaluation:**\n",
    "- Apply best model on test images (251‚Äì347)\n",
    "- Submit predictions in CSV format\n",
    "\n",
    "**Optional (Extra Credit):**\n",
    "- Up to 2 supervised DL models trained on raw images\n",
    "- Up to 2 models predicting `species` instead of just `bug type`\n",
    "\n",
    "---\n",
    "\n",
    "## Tips\n",
    "- Use quality metrics to evaluate each model.\n",
    "- Justify your choice of features and models.\n",
    "- Keep your report clear and reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ecb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction and data treatment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from skimage import measure\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190cff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# biblioth√®que pour la partie projection des donn√©es\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "# biblioth√®que pour la partie clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ebf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numbers(filename):\n",
    "    # Use regex to find all numbers in the filename\n",
    "    match = re.findall(r'\\d+', filename)\n",
    "    if match:\n",
    "        return int(match[0])\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "img_path = 'train/images/'\n",
    "mask_path = 'train/masks/'\n",
    "\n",
    "\n",
    "\n",
    "images = sorted([f for f in os.listdir(img_path) if f.endswith('.JPG')],\n",
    "                key=lambda f: extract_numbers(f)) \n",
    "masks = sorted([f for f in os.listdir(mask_path) if f.endswith('.tif')],\n",
    "               key=lambda f: extract_numbers(f))\n",
    "#print(f\"Sorted images: {images[:10]}\")  # Affiche les 10 premi√®res images tri√©es\n",
    "#print(f\"Sorted masks: {masks[:10]}\")\n",
    "\n",
    "image_numbers = sorted([extract_numbers(f) for f in images])\n",
    "mask_numbers = sorted([extract_numbers(f) for f in masks])\n",
    "\n",
    "missing_mask_numbers = set(image_numbers) - set(mask_numbers)\n",
    "missing_image_numbers = set(mask_numbers) - set(image_numbers)\n",
    "\n",
    "if missing_mask_numbers:\n",
    "    print(\"Image(s) sans masque correspondant :\", missing_mask_numbers)\n",
    "    print(\"Nom(s) de fichier image concern√©(s) :\")\n",
    "    for img in images:\n",
    "        if extract_numbers(img) in missing_mask_numbers:\n",
    "            print(\"  -\", img)\n",
    "\n",
    "if missing_image_numbers:\n",
    "    print(\"Masque(s) sans image correspondante :\", missing_image_numbers)\n",
    "    print(\"Nom(s) de fichier masque concern√©(s) :\")\n",
    "    for mask in masks:\n",
    "        if extract_numbers(mask) in missing_image_numbers:\n",
    "            print(\"  -\", mask)\n",
    "\n",
    "if 154 in image_numbers:\n",
    "    image_numbers.remove(154)\n",
    "    # Supprimer l'image correspondante de images\n",
    "    images = [img for img in images if extract_numbers(img) != 154]\n",
    "    # Supprimer aussi le masque correspondant si n√©cessaire\n",
    "    masks = [mask for mask in masks if extract_numbers(mask) != 154]\n",
    "\n",
    "print(\"Image numbers:\", len(image_numbers))\n",
    "print(\"Mask numbers:\", len(mask_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9cfe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "if len(image_numbers) != len(mask_numbers):\n",
    "    print(f\"Warning: Number of images ({len(images)}) does not match number of masks ({len(masks)})\")\n",
    "\n",
    "min_length = min(len(images), len(masks))\n",
    "\n",
    "\n",
    "for i in range (min_length):\n",
    "    # Extract features from the image and mask\n",
    "    #print(f\"Processing image: {image}\")\n",
    "    #print(f\"Processing mask: {mask}\")\n",
    "\n",
    "    img = cv2.imread(os.path.join(img_path, images[i]))\n",
    "    mask_img = cv2.imread(os.path.join(mask_path, masks[i]), 0)\n",
    "\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Error loading image: {images[i]}\")\n",
    "        continue  # Passer √† l'image suivante\n",
    "\n",
    "    if mask_img is None:\n",
    "        print(f\"Error loading mask: {mask[i]}\")\n",
    "        continue  # Passer √† l'image suivante\n",
    "\n",
    "    shappe_img = img.shape\n",
    "    shappe_mask = mask_img.shape\n",
    "\n",
    "    if shappe_img[0] != shappe_mask[0] or shappe_img[1] != shappe_mask[1]:\n",
    "        mask = cv2.resize(mask_img, (shappe_img[1], shappe_img[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    ratio = mask_img.sum() / (shappe_mask[0] * shappe_mask[1])\n",
    "\n",
    "    bug_Area = img[mask_img >0]\n",
    "    if bug_Area.size == 0:  \n",
    "        print(f\"No bug area detected in mask: {mask}\")\n",
    "        continue\n",
    "\n",
    "    r, g, b = bug_Area[:, 0], bug_Area[:, 1], bug_Area[:, 2]\n",
    "    bug_Area_size= np.count_nonzero(mask_img)\n",
    "\n",
    "    rgb_features = {\"r_min\": r.min(),\"r_max\": r.max(), \"r_mean\": r.mean(),\"r_median\":np.median(r), \"r_std\": r.std(),\n",
    "                    \"g_min\": g.min(),\"g_max\": g.max(), \"g_mean\": g.mean(), \"g_median\":np.median(g),\"g_std\": g.std(),\n",
    "                    \"b_min\": b.min(),\"b_max\": b.max(), \"b_mean\": b.mean(), \"b_median\":np.median(b),\"b_std\": b.std()}\n",
    "    \n",
    "    contours = measure.find_contours(mask_img, 0.5)\n",
    "    valid_contours = [c for c in contours if len(c) >= 3]\n",
    "\n",
    "    if valid_contours:\n",
    "        contour = max(valid_contours, key=lambda c: cv2.contourArea(np.array(c, dtype=np.float32)))\n",
    "        contour  = np.array(contour.astype(np.float32))\n",
    "\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "        hull = cv2.convexHull(contour)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "\n",
    "        convex_ratio = contour_area / hull_area if hull_area > 0 else 0\n",
    "        excentricity = contour_area / (np.pi * (bug_Area_size / np.pi) ** 2) if bug_Area_size > 0 else 0\n",
    "    else:\n",
    "        convex_ratio = 0\n",
    "        exentricity = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = {\n",
    "        \"img_name\": images[i],\n",
    "        \"mask_name\": masks[i],\n",
    "        \"img_shape_0\": shappe_img[0],\n",
    "        \"img_shape_1\": shappe_img[1],\n",
    "        \"mask_shape_0\": shappe_mask[0],\n",
    "        \"mask_shape_1\": shappe_mask[1],\n",
    "        \"ratio\": ratio,\n",
    "        \"convex_ratio\": convex_ratio,\n",
    "        \"exentricity\": excentricity\n",
    "    }\n",
    "\n",
    "all_features.update(rgb_features)\n",
    "features.append(all_features)\n",
    "\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "features_df.to_csv('features.csv', index=False)\n",
    "features_df.to_excel(\"features.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0fd2b",
   "metadata": {},
   "source": [
    "================ II. Maintenant qu'on a extrait les features, on peut visualiser les donn√©es =============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0efcb6",
   "metadata": {},
   "source": [
    "================= R√©partition des types d'insectes et des esp√®ces ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019379b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.read_excel(\"train/classif.xlsx\")\n",
    "print(\"df_class.shape:\", df_class.shape)\n",
    "df_class = df_class[df_class['ID'] != 154]\n",
    "print(\"df_class.shape:\", df_class.shape)\n",
    "\n",
    "bug_type_count = df_class['bug type'].value_counts()\n",
    "print(\"bug_type_count:\", bug_type_count)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bug_type_count.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"R√©partition des types d'insectes\")\n",
    "plt.xlabel('Esp√®ce')\n",
    "plt.ylabel('Nombre')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "species_count = df_class['species'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "species_count.plot(kind='bar', color='salmon')\n",
    "plt.title('R√©partition des esp√®ces')\n",
    "plt.xlabel('Esp√®ce')\n",
    "plt.ylabel('Nombre')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7fe9f",
   "metadata": {},
   "source": [
    "========== Ici On effectue une projection PCA sur les features extraites ============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb644d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = features_df.select_dtypes(include=[np.number])\n",
    "\n",
    "def variances(df):\n",
    "    variances = df.var()\n",
    "    return variances\n",
    "\n",
    "vars = variances(numeric_df)\n",
    "\n",
    "def standardize_data(df):\n",
    "    return (df - df.mean()) / df.std()\n",
    "\n",
    "standardized_df = standardize_data(numeric_df)\n",
    "\n",
    "centered_data = standardized_df\n",
    "\n",
    "def covariance_matrix(df):\n",
    "    nb_col = df.shape[1]\n",
    "    cov_matrix = np.zeros((nb_col, nb_col))\n",
    "    for i in range(nb_col):\n",
    "        for j in range(nb_col):\n",
    "            cov_matrix[i][j] = df.iloc[:, i].cov(df.iloc[:, j])\n",
    "    return cov_matrix\n",
    "\n",
    "cov_matrix = covariance_matrix(centered_data)\n",
    "\n",
    "def eigen_decomposition(cov_matrix):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "eigenvalues, eigenvectors = eigen_decomposition(cov_matrix)\n",
    "\n",
    "def sort_eigenvalues(eigenvalues, eigenvectors):\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_values = eigenvalues[sorted_indices]\n",
    "    sorted_vectors = eigenvectors[:, sorted_indices]\n",
    "    return sorted_values, sorted_vectors\n",
    "\n",
    "sorted_eigenvalues, sorted_eigenvectors = sort_eigenvalues(eigenvalues, eigenvectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_principal_components(eigenvalues, eigenvectors, k):\n",
    "    select_eigenvalues = eigenvalues[:k]\n",
    "    select_eigenvectors = eigenvectors[:, :k]\n",
    "    return select_eigenvalues, select_eigenvectors\n",
    "\n",
    "selected_values, selected_vectors = select_principal_components(sorted_eigenvalues, sorted_eigenvectors, 2)\n",
    "\n",
    "def project_data(df, eigenvectors):\n",
    "    return np.dot(df.values, eigenvectors)\n",
    "\n",
    "projected_data = project_data(centered_data, selected_vectors)\n",
    "print(\"projected_data.shape:\", projected_data.shape)\n",
    "#df_class = df_class.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def plot_pca(projected_data, df_class):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=projected_data[:, 0], y=projected_data[:, 1], hue=df_class['bug type'], palette='Set1')\n",
    "    plt.title('PCA Projection of Features')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(title='Bug Type')\n",
    "    plt.show()\n",
    "    \n",
    "plot_pca(projected_data, df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K  = 6\n",
    "kmeans = KMeans(n_clusters=K, random_state=42)\n",
    "clusters = kmeans.fit_predict(projected_data)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(projected_data[:, 0], projected_data[:, 1], c=clusters, cmap='tab10', s=30)\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"PCA Projection with K-means Clusters\")\n",
    "plt.colorbar(scatter, label=\"Cluster ID\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d948a",
   "metadata": {},
   "source": [
    "=========== Maintenant qu'on a r√©alis√© le pca, on va explorer une autre m√©thode de projection =========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f5648",
   "metadata": {},
   "source": [
    "========== On va utiliser t-SNE pour projeter les donn√©es dans un espace 2D =========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30, random_state=0)\n",
    "tsne_projected = tsne.fit_transform(numeric_df)\n",
    "\n",
    "tsne_df = pd.DataFrame({\n",
    "    't-SNE 1': tsne_projected[:, 0],\n",
    "    't-SNE 2': tsne_projected[:, 1],\n",
    "    'bug type': df_class['bug type'].values\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=tsne_df,\n",
    "    x='t-SNE 1',\n",
    "    y='t-SNE 2',\n",
    "    hue='bug type',\n",
    "    palette='Set1',\n",
    "    alpha=0.7,\n",
    "    edgecolor='k'\n",
    ")\n",
    "\n",
    "plt.title(\"t-SNE projection of features by bug type\")\n",
    "plt.xlabel(\"t-SNE 1 (no unit)\")\n",
    "plt.ylabel(\"t-SNE 2 (no unit)\")\n",
    "plt.legend(title=\"Bug Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28d65da",
   "metadata": {},
   "source": [
    "========== On va maintenant essayer d'utiliser UMAP pour projeter les donn√©es dans un espace 2D =========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state=0)\n",
    "umap_projected = reducer.fit_transform(numeric_df)\n",
    "\n",
    "umap_df = pd.DataFrame({\n",
    "    'UMAP 1': umap_projected[:, 0],\n",
    "    'UMAP 2': umap_projected[:, 1],\n",
    "    'bug type': df_class['bug type'].values\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x='UMAP 1',\n",
    "    y='UMAP 2',\n",
    "    hue='bug type',\n",
    "    palette='Set2',\n",
    "    alpha=0.8,\n",
    "    edgecolor='k'\n",
    ")\n",
    "\n",
    "plt.title(\"UMAP projection of features by bug type\")\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(title=\"Bug Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ddaf87",
   "metadata": {},
   "source": [
    "========== Dans cette partie on va faire un clustering sur les donn√©es projet√©es =========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f3ae6",
   "metadata": {},
   "source": [
    "1. KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21de4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = projected_data , df_class['bug type'].values\n",
    "\n",
    "kmeans = KMeans(n_clusters =bug_type_count.shape[0], random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "X_with_clusters = X.copy()\n",
    "X_with_clusters = np.column_stack((X_with_clusters, clusters))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_clusters, y, test_size=0.3, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "accuracy = log_reg.score(X_test, y_test)\n",
    "print(f\"Accuracy of Logistic Regression on KMeans clusters: {accuracy:.2f}\")\n",
    "\n",
    "score = silhouette_score(X_with_clusters, clusters) # sert √† mesurer la coh√©rence des clusters\n",
    "print(f\"Silhouette Score: {score:.2f}\") # plus il est proche de 1, mieux c'est\n",
    "\n",
    "# Pour les r√©sultats : plus de chevauchement entre les clusters pour X = projected_data donc score faible\n",
    "# Groupes bien s√©par√©s pour X = umap_projected donc score √©lev√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac863a4",
   "metadata": {},
   "source": [
    "2. DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc22b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = projected_data\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n",
    "labels = clusterer.fit_predict(X)\n",
    "\n",
    "score = silhouette_score(X, labels)\n",
    "print(f\"Silhouette Score: {score:.2f}\") \n",
    "\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(f\"HDBSCAN ‚Üí Clusters: {n_clusters}, Silhouette Score: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
